{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pprint\n",
    "import tempfile\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from six import BytesIO\n",
    "from IPython import display\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import orbit\n",
    "import tensorflow_models as tfm\n",
    "\n",
    "from official.core import exp_factory\n",
    "from official.core import config_definitions as cfg\n",
    "from official.vision.serving import export_saved_model_lib\n",
    "from official.vision.ops.preprocess_ops import normalize_image\n",
    "from official.vision.ops.preprocess_ops import resize_and_crop_image\n",
    "from official.vision.utils.object_detection import visualization_utils\n",
    "from official.vision.dataloaders.tf_example_decoder import TfExampleDecoder\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4) # Set Pretty Print Indentation\n",
    "print(tf.__version__) # Check the version of tensorflow used\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone --quiet https://github.com/tensorflow/models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L 'https://public.roboflow.com/ds/ZpYLqHeT0W?key=ZXfZLRnhsc' > './BCCD.v1-bccd.coco.zip'\n",
    "!unzip -q -o './BCCD.v1-bccd.coco.zip' -d './BCC.v1-bccd.coco/'\n",
    "!rm './BCCD.v1-bccd.coco.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "TRAIN_DATA_DIR='../BCC.v1-bccd.coco/train'\n",
    "TRAIN_ANNOTATION_FILE_DIR='../BCC.v1-bccd.coco/train/_annotations.coco.json'\n",
    "OUTPUT_TFRECORD_TRAIN='../bccd_coco_tfrecords/train'\n",
    "\n",
    "# Need to provide\n",
    "  # 1. image_dir: where images are present\n",
    "  # 2. object_annotations_file: where annotations are listed in json format\n",
    "  # 3. output_file_prefix: where to write output convered TFRecords files\n",
    "python -m official.vision.data.create_coco_tf_record --logtostderr \\\n",
    "  --image_dir=${TRAIN_DATA_DIR} \\\n",
    "  --object_annotations_file=${TRAIN_ANNOTATION_FILE_DIR} \\\n",
    "  --output_file_prefix=$OUTPUT_TFRECORD_TRAIN \\\n",
    "  --num_shards=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "TEST_DATA_DIR='../BCC.v1-bccd.coco/test'\n",
    "TEST_ANNOTATION_FILE_DIR='../BCC.v1-bccd.coco/test/_annotations.coco.json'\n",
    "OUTPUT_TFRECORD_TEST='../bccd_coco_tfrecords/test'\n",
    "\n",
    "python -m official.vision.data.create_coco_tf_record --logtostderr \\\n",
    "  --image_dir=$TEST_DATA_DIR \\\n",
    "  --object_annotations_file=$TEST_ANNOTATION_FILE_DIR \\\n",
    "  --output_file_prefix=$OUTPUT_TFRECORD_TEST \\\n",
    "  --num_shards=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_input_path = '../bccd_coco_tfrecords/train-00000-of-00001.tfrecord'\n",
    "valid_data_input_path = '../bccd_coco_tfrecords/valid-00000-of-00001.tfrecord'\n",
    "test_data_input_path = '../bccd_coco_tfrecords/test-00000-of-00001.tfrecord'\n",
    "model_dir = '../trained_model/'\n",
    "export_dir ='../exported_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config = exp_factory.get_exp_config('retinanet_resnetfpn_coco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_classes = 3\n",
    "\n",
    "HEIGHT, WIDTH = 256, 256\n",
    "IMG_SIZE = [HEIGHT, WIDTH, 3]\n",
    "\n",
    "# Backbone config.\n",
    "exp_config.task.freeze_backbone = False\n",
    "exp_config.task.annotation_file = ''\n",
    "\n",
    "# Model config.\n",
    "exp_config.task.model.input_size = IMG_SIZE\n",
    "exp_config.task.model.num_classes = num_classes + 1\n",
    "exp_config.task.model.detection_generator.tflite_post_processing.max_classes_per_detection = exp_config.task.model.num_classes\n",
    "\n",
    "# Training data config.\n",
    "exp_config.task.train_data.input_path = train_data_input_path\n",
    "exp_config.task.train_data.dtype = 'float32'\n",
    "exp_config.task.train_data.global_batch_size = batch_size\n",
    "exp_config.task.train_data.parser.aug_scale_max = 1.0\n",
    "exp_config.task.train_data.parser.aug_scale_min = 1.0\n",
    "\n",
    "# Validation data config.\n",
    "exp_config.task.validation_data.input_path = valid_data_input_path\n",
    "exp_config.task.validation_data.dtype = 'float32'\n",
    "exp_config.task.validation_data.global_batch_size = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logical_device_names = [logical_device.name for logical_device in tf.config.list_logical_devices()]\n",
    "\n",
    "if 'GPU' in ''.join(logical_device_names):\n",
    "  print('This may be broken in Colab.')\n",
    "  device = 'GPU'\n",
    "elif 'TPU' in ''.join(logical_device_names):\n",
    "  print('This may be broken in Colab.')\n",
    "  device = 'TPU'\n",
    "else:\n",
    "  print('Running on CPU is slow, so only train for a few steps.')\n",
    "  device = 'CPU'\n",
    "\n",
    "\n",
    "train_steps = 1000\n",
    "exp_config.trainer.steps_per_loop = 100 # steps_per_loop = num_of_training_examples // train_batch_size\n",
    "\n",
    "exp_config.trainer.summary_interval = 100\n",
    "exp_config.trainer.checkpoint_interval = 100\n",
    "exp_config.trainer.validation_interval = 100\n",
    "exp_config.trainer.validation_steps =  100 # validation_steps = num_of_validation_examples // eval_batch_size\n",
    "exp_config.trainer.train_steps = train_steps\n",
    "exp_config.trainer.optimizer_config.warmup.linear.warmup_steps = 100\n",
    "exp_config.trainer.optimizer_config.learning_rate.type = 'cosine'\n",
    "exp_config.trainer.optimizer_config.learning_rate.cosine.decay_steps = train_steps\n",
    "exp_config.trainer.optimizer_config.learning_rate.cosine.initial_learning_rate = 0.1\n",
    "exp_config.trainer.optimizer_config.warmup.linear.warmup_learning_rate = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(exp_config.as_dict())\n",
    "display.Javascript('google.colab.output.setIframeHeight(\"500px\");')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exp_config.runtime.mixed_precision_dtype == tf.float16:\n",
    "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "if 'GPU' in ''.join(logical_device_names):\n",
    "  distribution_strategy = tf.distribute.MirroredStrategy()\n",
    "elif 'TPU' in ''.join(logical_device_names):\n",
    "  tf.tpu.experimental.initialize_tpu_system()\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='/device:TPU_SYSTEM:0')\n",
    "  distribution_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "  print('Warning: this will be really slow.')\n",
    "  distribution_strategy = tf.distribute.OneDeviceStrategy(logical_device_names[0])\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with distribution_strategy.scope():\n",
    "  task = tfm.core.task_factory.get_task(exp_config.task, logging_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in task.build_inputs(exp_config.task.train_data).take(1):\n",
    "  print()\n",
    "  print(f'images.shape: {str(images.shape):16}  images.dtype: {images.dtype!r}')\n",
    "  print(f'labels.keys: {labels.keys()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index={\n",
    "    1: {\n",
    "        'id': 1,\n",
    "        'name': 'Platelets'\n",
    "       },\n",
    "    2: {\n",
    "        'id': 2,\n",
    "        'name': 'RBC'\n",
    "       },\n",
    "    3: {\n",
    "        'id': 3,\n",
    "        'name': 'WBC'\n",
    "       }\n",
    "}\n",
    "tf_ex_decoder = TfExampleDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(raw_records, num_of_examples):\n",
    "  plt.figure(figsize=(20, 20))\n",
    "  use_normalized_coordinates=True\n",
    "  min_score_thresh = 0.30\n",
    "  for i, serialized_example in enumerate(raw_records):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    decoded_tensors = tf_ex_decoder.decode(serialized_example)\n",
    "    image = decoded_tensors['image'].numpy().astype('uint8')\n",
    "    scores = np.ones(shape=(len(decoded_tensors['groundtruth_boxes'])))\n",
    "    visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image,\n",
    "        decoded_tensors['groundtruth_boxes'].numpy(),\n",
    "        decoded_tensors['groundtruth_classes'].numpy().astype('int'),\n",
    "        scores,\n",
    "        category_index=category_index,\n",
    "        use_normalized_coordinates=use_normalized_coordinates,\n",
    "        max_boxes_to_draw=200,\n",
    "        min_score_thresh=min_score_thresh,\n",
    "        agnostic_mode=False,\n",
    "        instance_masks=None,\n",
    "        line_thickness=4)\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Image-{i+1}')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 20\n",
    "num_of_examples = 3\n",
    "\n",
    "raw_records = tf.data.TFRecordDataset(\n",
    "    exp_config.task.train_data.input_path).shuffle(\n",
    "        buffer_size=buffer_size).take(num_of_examples)\n",
    "show_batch(raw_records, num_of_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, eval_logs = tfm.core.train_lib.run_experiment(\n",
    "    distribution_strategy=distribution_strategy,\n",
    "    task=task,\n",
    "    mode='train_and_eval',\n",
    "    params=exp_config,\n",
    "    model_dir=model_dir,\n",
    "    run_post_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir '../trained_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_saved_model_lib.export_inference_graph(\n",
    "    input_type='image_tensor',\n",
    "    batch_size=1,\n",
    "    input_image_size=[HEIGHT, WIDTH],\n",
    "    params=exp_config,\n",
    "    checkpoint_path=tf.train.latest_checkpoint(model_dir),\n",
    "    export_dir=export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "  \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "  Puts image into numpy array to feed into tensorflow graph.\n",
    "  Note that by convention we put it into a numpy array with shape\n",
    "  (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "  Args:\n",
    "    path: the file path to the image\n",
    "\n",
    "  Returns:\n",
    "    uint8 numpy array with shape (img_height, img_width, 3)\n",
    "  \"\"\"\n",
    "  image = None\n",
    "  if(path.startswith('http')):\n",
    "    response = urlopen(path)\n",
    "    image_data = response.read()\n",
    "    image_data = BytesIO(image_data)\n",
    "    image = Image.open(image_data)\n",
    "  else:\n",
    "    image_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "    image = Image.open(BytesIO(image_data))\n",
    "\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (1, im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "def build_inputs_for_object_detection(image, input_image_size):\n",
    "  \"\"\"Builds Object Detection model inputs for serving.\"\"\"\n",
    "  image, _ = resize_and_crop_image(\n",
    "      image,\n",
    "      input_image_size,\n",
    "      padded_size=input_image_size,\n",
    "      aug_scale_min=1.0,\n",
    "      aug_scale_max=1.0)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_examples = 3\n",
    "\n",
    "test_ds = tf.data.TFRecordDataset(\n",
    "    '../bccd_coco_tfrecords/test-00000-of-00001.tfrecord').take(\n",
    "        num_of_examples)\n",
    "show_batch(test_ds, num_of_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported = tf.saved_model.load(export_dir)\n",
    "model_fn = imported.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_size = (HEIGHT, WIDTH)\n",
    "plt.figure(figsize=(20, 20))\n",
    "min_score_thresh = 0.30 # Change minimum score for threshold to see all bounding boxes confidences.\n",
    "\n",
    "for i, serialized_example in enumerate(test_ds):\n",
    "  plt.subplot(1, 3, i+1)\n",
    "  decoded_tensors = tf_ex_decoder.decode(serialized_example)\n",
    "  image = build_inputs_for_object_detection(decoded_tensors['image'], input_image_size)\n",
    "  image = tf.expand_dims(image, axis=0)\n",
    "  image = tf.cast(image, dtype = tf.uint8)\n",
    "  image_np = image[0].numpy()\n",
    "  result = model_fn(image)\n",
    "  visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np,\n",
    "      result['detection_boxes'][0].numpy(),\n",
    "      result['detection_classes'][0].numpy().astype(int),\n",
    "      result['detection_scores'][0].numpy(),\n",
    "      category_index=category_index,\n",
    "      use_normalized_coordinates=False,\n",
    "      max_boxes_to_draw=200,\n",
    "      min_score_thresh=min_score_thresh,\n",
    "      agnostic_mode=False,\n",
    "      instance_masks=None,\n",
    "      line_thickness=4)\n",
    "  plt.imshow(image_np)\n",
    "  plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
